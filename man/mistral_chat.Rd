% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mistral_chat.R
\name{mistral_chat}
\alias{mistral_chat}
\title{Wrapper function to chat with an LLM (here, mistral-tiny)}
\usage{
mistral_chat(
  prompt,
  model = "mistral-tiny",
  temperature = 0.7,
  max_tokens = 100,
  api_key = NULL
)
}
\arguments{
\item{prompt}{The text prompt to send to the Mistral API.}

\item{model}{The model to use (default: "mistral-tiny").}

\item{temperature}{Controls randomness in the response (default: 0.7).}

\item{max_tokens}{Maximum number of tokens in the response (default: 100).}

\item{api_key}{Your Mistral API key (optional, can be set globally).}
}
\value{
The API response as a character string.
}
\description{
Sends a prompt to the Mistral API and returns the response.
}
\examples{
mistral_chat("How do you spell backward backward?")

}
